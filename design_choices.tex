\section{Design Choices}

We discus three main overarching design choices that one has to make when integrating ML components with DBMSs: 1) external vs. internal integration, 2)  learning from workloads vs. data and 3) choice of ML paradigm.


\subsection{External vs. Internal Integration}
We found that there are two main engineering approaches for integrating ML components in to DBMSs: external vs. internal integration ~\cite{pavlo2019external}.

\vspace{2mm}
\noindent \textbf{External Integration.} Modern DBMSs are complex systems and they allow human database administrators to control the query execution performance by: (1) optimizing the physical database design, (2) providing query optimization hints, (3) knob tuning, and (4) resource provisioning.
They also provide information about the system such as resource usage, query traces, and performance metrics.
In this context the focus of externally integrated ML components is to provide recommendations to human database administrators or replace them and automatically perform the tasks using the standard configuration endpoints provided by the DBMS.

An enterprise-grade DBMS typically requires decades of highly advanced software development efforts and thus there is huge resistance among DBMS developers to integrate new components that require significant architectural changes.
External integration keeps the ML components outside the critical path of a DBMS and is still provides a value.
For this reason, systems that follow the external integration paradigm have been successfully adopted by several enterprise DBMSs.

However, external integration also faces several limitations.
First developing multiple external components that operate on different sub-problem may lead to interference among the decisions taken by those systems.
For example assume an external query optimization component which hints a specific query plan the to DBMS assuming the absence of a particular index.
At the same time assume there is a another physical database design component that decides to create this index which renders the chosen evaluation plan become sub-optimal.
Avoiding this kind of inferences requires coordination among different components, which is difficult to implement in external components.
Second, external components for knob tuning and resource provisioning takes an iterative approach where they tryout number of different settings before picking the best option.
Existing DBMSs are not optimized for such rapid experimentation and hence requires system down times or restarts for the configurations to take effect.
This significantly increases the time required for knob tuning by an ML component.
Finally, the system information metrics provided by the DBMSs are primarily intended to be consumed by human database administrators for diagnosing performance bottlenecks.
Thus they can be too high-level for ML components to learn from.


\vspace{2mm}
\noindent \textbf{Internal Integration.} 
Internal integration of ML components tries to mitigate much of the above mentioned limitations by changing the DBMS architecture to treat ML components as first class citizens.
As a result ML components get more access to the low level information and more fine-grained control to the DBMS.
Coherence among the decisions taken by multiple ML components inside a DBMS can be achieved by having a centralized coordinator that takes suggested actions from different ML components and execute them only if they don't interfere with other decisions.

However, internal integration requires tight coupling between the components inside a DBMS and can pose query execution performance degradation when training the ML models.
Hence, they are mostly applicable for new data system developments which are being developed from scratch (also called greenfield systems).
In fact several vision systems have already proposed novel learned DBMS architectures.

NoisePage~\cite{noisepage} is an in-memory  hybrid transitional and analytic processing DBMS, which can automatically optimize query execution without a human database administrator.
Currently it can handle knob tuning, resource provisioning, and physical database design optimization.
It has a modular architecture optimized for efficient offline training data collection by ML components.
Training data for each module (e.g., transaction manager) can be obtained in isolation without the need of going through the entire DBMS execution path.
These offline collected data is then combined with the data collected through online query execution to learn ML models.
The ML pipeline in NoisePage has three main phases: 1) modeling, 2) planning, 3) deployment.
In modeling stage it builds models to predict the future query workload and models to predict the behavior of system components under different configuration values.
In the planning stage it uses reinforcement learning to pick actions based on the models trained in the modeling phase, instead of interacting with the actual system.
Finally, in the deployment phase the chosen actions are applied and the observed performance metrics are later fed back to modelling and planning models to improve their performance.

SageDB~\cite{sagedb} is another system which proposes a novel DBMS architecture that uses ML models combined with program synthesis techniques to generate internal system components like data structures and algorithms.
In order to balance the execution time vs. accuracy it proposes using multiple ML models each specialized for a particular task.
ML models in SageDB are optimized to capture the empirical data distribution of the data and not optimized for the ability to generalize to unseen data.
In SageDB, these synthesized systems components are  used for optimizing data access (e.g., indices), query optimization (e.g., cardinality estimation), and query execution (e.g., sorting).


\subsection{Learning from Workloads vs. Data} 
The main goal of using ML for DBMS components is to improve the performance of the system for future query workloads.
Thus one way for adopting ML methods is to learn from past or current (in the case of reinforcement learning) queries.
But the performance of the queries is dependant on the state of the underlying data in the DBMS.
Hence, in some cases, it is also possible to achieve the same goal by learning from the data.
Next we explain some of the popular systems which adopts these two approaches and compare their pros and cons.

\vspace{2mm}
\noindent \textbf{Learning from Workloads.} Learning from workloads is the most widely used approach for integrating ML into DBMS across all components.
For example, Seq2SQL~\cite{seq2sql} and SQLNet~\cite{sqlnet} use sample SQL query and natural language query pairs to learn an ML model to compile natural language queries into SQL queries.
VerdictDB~\cite{verdict} learns from the results of past AQP queries to provide better error guarantees or reduce runtimes of future AQP queries.
Systems like LEO~\cite{leo}, CardLearner~\cite{cardlearner}, QPPNet~\cite{qppnet}, and AutoAdmin~\cite{autoadmin} learns from past or current queries in order to improve the relational engine of the DBMS.
OtterTune ~\cite{ottertune} and Bandit~\cite{bandit} also learns from past queries to optimizer for future queries.
Learning from queries enable the ML models to learn a narrow scoped problem which is much easier to model/learn and hence improve the overall performance of the system.
However, this approach faces three main challenges.
First, collecting training data for this approach can be expensive as each query needs to be executed on large databases.
Second, it does not generalize well for unseen workload queries and cause significant performance degradation at execution time.
Third, changes in the workload patterns or underlying data requires capturing new training data and expensive retraining which can cause system downtime.

\vspace{2mm}
\noindent \textbf{Learning from Data.} More recently data-driven ML methods have been suggested.
These methods train models to learn the joint probability distribution of the data and use these models to improve the DBMS performance.
For example, DBEst~\cite{dbest} and DeepDB~\cite{deepdb} uses probability distribution models to answer AQP queries.
Naru~\cite{naru} and DeepDB~\cite{deepdb} use probability distribution models in the relational engine to optimize cardinality estimates.
They are also the main building block in learned data structures and algorithms such Learned Index~\cite{learnedindex}, FITing-Tree~\cite{fitingtree}, and XIndex~\cite{xindex}.
These probability distribution models can be reused despite changes in the workload pattern.
They are also more robust to small changes in the DBMS data.
More importantly, \cite{deepdb} has shown that the same probability distribution model can used in multiple tasks such as AQP and cardinality estimation, reducing the total training time required.
However, accurately capturing the joint probability distribution of a relational dataset with multiple tables a complex learning task which requires models with high learning capacity and training time.
Furthermore, not all DBMS components can be purely learned from data (e.g., execution engine knob tuning).

\vspace{2mm}
\noindent \textbf{Hybrid Methods.} While most of the existing systems falls into one of the above two approaches, it would be interesting to explore possibility of combining both approaches.
Some early work in this regard has been proposed in the XIndex~\cite{xindex} system.
XIndex is a learned index structure which replaces B-tree indices.
It does so by learning the empirical cumulative distribution function of the keys of the data.
During training the goal is to minimize the maximum error made by the model for predicting the position of a key.
But the performance of a particular workload will be dominated by the errors made by the model on the keys that are frequently used in the workload.
Hence, XIndex performs second phase of learning where it dynamically further minimizes the error on the most frequently used keys.


\subsection{Choice of the ML Paradigm}
