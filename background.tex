\section{Background}
We provide some background on the database management system internals and machine learning methods to help understand the rest of this paper.

\subsection{Database Management Systems}
We identify three main components of an RDBMS: 1) query parser, 2) relational engine, and 3) execution engine.
To give a brief introduction to each of these components, we next explain the journey of a typical SQL query.

\vspace{2mm}
\noindent \textbf{Query Parser.} Alice is a data analyst at an online e-commerce website and she wants to find the top 10 products in terms of sales revenue.
She writes a SQL query using the SQL client in her laptop and submits it to the RDMBS for execution.
At the RDBMS, the SQL query will be first intercepted by the query parser.
The query parser will verify the query is 1) free from syntax and semantic errors, verify the user is authorized to execute the query, and 3) convert the query into the internal format used by the system which is equivalent to a relational algebra statement.

\vspace{2mm}
\noindent \textbf{Relational Engine.} The parsed query is then sent to the relational engine which outputs an optimal query evaluation plan (QEP) for the given query.
It does so by searching the space of equivalent query evaluation plan space and estimating the cost of each option.
For this task, it relies on the metadata information and statistics about the data, which are generated beforehand.
QEP dictates the order of execution for each operator and which physical operator implementation to be used.

\vspace{2mm}
\noindent \textbf{Execution Engine.} Finally, the QEP is sent to the execution engine for execution, which is responsible for managing all the low-level systems resources such as memory buffers and thread pools, accessing the data and indices, and coordinating the execution of the query either on a single machine or on multiple machines.
It also handles concurrency control and failure recovery of the RDBMS.
The output generated by executing the query is sent back to Alice.

\vspace{2mm}
\noindent \textbf{Database Administrator.} Being complex software systems, RDBMSs require a significant amount of tuning in order to achieve good performance for a particular use case.
To worsen the situation, the set of default configurations in the RDBMS are often obsolete and does not match the resource availability of modern hardware (e.g., MySQL default buffer pool size is 128MB!).
Thus, in Alice's use case, the RDBMS has to be tuned to the schema of the database and the set of widely used queries by the analysts in her company.
Furthermore, for query optimization tasks the relevant data statistics have to be generated and kept up to date.
Typically, these tasks are performed by a database administrator who has specialized knowledge about the internals of the RDBMS.


\subsection{Machine Learning Methods}
For the purpose of this paper, we divide machine learning into two major model families: 1) deep learning and 2) classical machine learning.

\vspace{2mm}
\noindent \textbf{Deep Learning. } Deep learning (DL)~\cite{dlbook} is the name given to the family of ML models that are composed of artificial neural networks (ANNs).
ANNs are inspired by the structure and function of the human brain.
They learn a hierarchy of parametric features using layers of various types (e.g., fully connected, ReLU).
All parameters are trained using a technique called back-propagation.
Training a deep learning model incurs massive costs: they typically need many GPUs for reasonable runtimes, huge labeled datasets, and complex hyper-parameter tuning.
Recently, DL methods have been able to produce superior accuracy results outperforming other ML methods on hard tasks like computer vision and natural language processing.
In some cases, they have even surpassed the human-level accuracy.

\vspace{2mm}
\noindent \textbf{Classical Machine Learning. } Despite many successes using DL-based ML methods, in many applications that involve working with structured data, ML model families like generalized linear models, decision tree models, and Bayesian models are widely used.
Typically, these model families are collectively referred to as \textit{classical machine learning}, a term coined to contrast them with DL models.
Unlike DL models, which can all be trained using back-propagation method, each sub-family in classical ML uses different statistical learning foundations and learning methods.
Furthermore, their characteristics are also significantly different among different sub-families.

For the above two ML model families, we further identify three different learning paradigms: 1) supervised learning, 2) unsupervised learning, and 3) reinforcement learning.

\vspace{2mm}
\noindent \textbf{Supervised Learning. } In supervised learning, the training data consists of a set of input (also called features) and output pairs.
The goal of the ML model is to learn a prediction function that takes in unseen inputs and predicts an output value such that the discrepancy between the predicted value and the actual value corresponding to the unseen input is minimized.
Supervised learning is applicable in settings where there is a direct observable mapping between input and output, a large amount of training data available, and we are confident that the training data covers the entire data distribution.

\vspace{2mm}
\noindent \textbf{Unsupervised Learning. } In unsupervised learning, the training data contains only the input and no explicit output.
The purpose of the ML model is to learn a function that can discern the latent structure of the inputs.
Given an unseen test input, the trained unsupervised ML model can be used to predict the structural properties of the input.
Popular applications of unsupervised learning include probability density function estimation and data clustering.

\vspace{2mm}
\noindent \textbf{Reinforcement Learning. } The goal of reinforcement learning methods is to learn a function that takes in an input state and generates an action that will maximize the overall cumulative reward (not the immediate reward).
Unlike supervised learning methods, they do not make any assumptions about the data generating process and also do not require a training set of state-action (input-output) pairs to be presented.
State-action pairs are generated as the model interacts with the environment and models use an explore-exploit paradigm to learn while being used to make predictions at the same time.
Reinforcement learning techniques are useful in settings where the reward of action is not directly observable and we want the model to try different things and pick the best option.
However, as there is no initial assumption on the data generating process (e.g., through training data), in some problems reinforcement learning method will fail or take a long time to learn.