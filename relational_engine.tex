\section{ML for Relational Engine}
Relational Engine is one of the most important components in a database management system,  that has been extensively studied for the last 40 years.
It takes in a query in the form of relational algebra expression and outputs a query evaluation plan, which will be evaluated by the underlying execution engine.
We identify three different sub-areas of ML applications in the relation engine: ML for (1) query optimization, (2) physical database design optimization, (3) approximate query processing.
Next, we discuss some of the most prominent work in each of these sub-areas.

\subsection{Query Optimization}

\noindent\textbf{Cardinality Estimation}

\noindent\textbf{Join Order Enumeration}

\subsection{Physical Database Design Optimization}


\subsection{Approximate Query Processing}
While the ever growing volumes of data enables us to glean unprecedented insights, the associated high computational and resource costs often becomes a bottleneck.
Approximate query processing (AQP) techniques try to mitigate this issue by generating approximate answers to the original query at a fraction of time and cost of the original query execution.
The conventional approach to AQP is to use query time data sampling and/or data statistics to answer queries.
After the query is executed the work done for that query is never reused.

Alternatively, machine learning techniques provide an interesting opportunity to learn from past query executions and use that learning to approximately answer future queries.
Every new query execution reveals some new information about the data and processing more and more queries over time reveals even more information.
Verdict \cite{verdict} is one of the very first systems to apply this technique in the context of AQP.
It uses a data structure called \textit{Query Synopsis} to store the past query results and uses it to refine the approximate answer generated by the system for every new query.
Thus Verdict is able to reduce to runtime required for an approximate query for specified error bound or reduce the error bound for an approximate query with a specified time budget.
Internally, Verdict uses the principle of maximum entropy to build a multivariate normal distribution model, which is in expectation yields superior results compared to just sampling-based techniques.
For the TPC-H benchmark dataset, Verdict can improve the runtime by 9x for a 4\% error bound and tighten the error bound by 85\% for a fixed time budget of 4 minutes.
However, Verdict can only support flat select-project-join style queries with no text predicated which only covers 14 of the 21 TPC-H queries.
Also, it cannot support updates and deletes.


